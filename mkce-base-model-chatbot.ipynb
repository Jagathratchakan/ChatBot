{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9189250,"sourceType":"datasetVersion","datasetId":5554865}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement\n\n**Our institution currently faces challenges in providing timely, accurate, and efficient support to students, faculty, and staff. The existing support systems, such as help desks and FAQs, are often overwhelmed, leading to long wait times, information overload, and decreased user satisfaction.**\n\n# Objective\n\n**To develop a sophisticated chatbot powered by deep learning to address these challenges by providing:**\n\n24/7 availability: Ensuring round-the-clock support without relying on human agents.\n\nImproved efficiency: Automating routine inquiries and reducing response times.\n\nEnhanced user experience: Offering a personalized and intuitive interaction.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-17T07:13:30.820939Z","iopub.execute_input":"2024-08-17T07:13:30.822092Z","iopub.status.idle":"2024-08-17T07:13:30.870532Z","shell.execute_reply.started":"2024-08-17T07:13:30.822047Z","shell.execute_reply":"2024-08-17T07:13:30.869089Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/chatbot-model/intents.json\n","output_type":"stream"}]},{"cell_type":"code","source":"#Import needed Libraries for ChatBot creation\n\nimport json\nimport random\n\nimport nltk.tokenize\nfrom nltk.stem.porter import PorterStemmer\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:30.873111Z","iopub.execute_input":"2024-08-17T07:13:30.873590Z","iopub.status.idle":"2024-08-17T07:13:35.478449Z","shell.execute_reply.started":"2024-08-17T07:13:30.873548Z","shell.execute_reply":"2024-08-17T07:13:35.477031Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Load Dataset in workspace\ndata_file = open('/kaggle/input/chatbot-model/intents.json').read()\nintents = json.loads(data_file)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.480031Z","iopub.execute_input":"2024-08-17T07:13:35.480598Z","iopub.status.idle":"2024-08-17T07:13:35.489443Z","shell.execute_reply.started":"2024-08-17T07:13:35.480561Z","shell.execute_reply":"2024-08-17T07:13:35.488189Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Natural Language Process\n\nstemmer = PorterStemmer()\n\nclass nltk_process:\n    def tokenize(sentence):\n        return nltk.tokenize.word_tokenize(sentence)\n\n    def stem(word):\n        return stemmer.stem(word.lower())\n\n    def bag_of_words(tokenized_sentence, all_words):\n        tokenized_sentence = [nltk_process.stem(w) for w in tokenized_sentence]\n\n        bag = np.zeros(len(all_words),dtype=np.float32)\n        for idx,w in enumerate(all_words):\n            if w in tokenized_sentence:\n                bag[idx] = 1.0\n        return bag","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.490980Z","iopub.execute_input":"2024-08-17T07:13:35.491396Z","iopub.status.idle":"2024-08-17T07:13:35.501270Z","shell.execute_reply.started":"2024-08-17T07:13:35.491337Z","shell.execute_reply":"2024-08-17T07:13:35.500026Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# FeedForwarding Neural Network\n\nclass NeuralNet(nn.Module):\n    def __init__(self,input_size,hidden_size,num_classess):\n        super(NeuralNet,self).__init__()\n        self.l1 = nn.Linear(input_size,hidden_size)\n        self.l2 = nn.Linear(hidden_size,hidden_size)\n        self.l3 = nn.Linear(hidden_size,hidden_size)\n        self.l4 = nn.Linear(hidden_size,num_classess)\n\n        self.relu = nn.ReLU()\n    \n    def forward(self,x):\n        out = self.l1(x)\n        out = self.relu(out)\n\n        out = self.l2(out)\n        out = self.relu(out)\n\n        out = self.l3(out)\n        out = self.relu(out)\n        \n        out = self.l4(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.504072Z","iopub.execute_input":"2024-08-17T07:13:35.504432Z","iopub.status.idle":"2024-08-17T07:13:35.514713Z","shell.execute_reply.started":"2024-08-17T07:13:35.504404Z","shell.execute_reply":"2024-08-17T07:13:35.513353Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Creating Dataset for Model training\n\nclass ChatDataset(Dataset):\n    def __init__(self) :\n        self.n_samples = len(x_train)\n        self.x_data = x_train\n        self.y_data = y_train\n    \n    def __getitem__(self, index):\n        return self.x_data[index],self.y_data[index]\n    \n    def __len__(self):\n        return self.n_samples","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.516275Z","iopub.execute_input":"2024-08-17T07:13:35.516717Z","iopub.status.idle":"2024-08-17T07:13:35.527570Z","shell.execute_reply.started":"2024-08-17T07:13:35.516684Z","shell.execute_reply":"2024-08-17T07:13:35.526156Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Prepare Data for Dataset\n\nall_words = []\ntags = []\nxy = []\nignore_words = ['?','.',',','!']\n\nfor intent in intents['intents']:\n    tag = intent['tag']\n    tags.append(tag)\n    for pattern in intent[\"patterns\"]:\n        w = nltk_process.tokenize(pattern)\n        all_words.extend(w)\n        xy.append((w,tag))\n\nall_words = [nltk_process.stem(w) for w in all_words if w not in ignore_words]\nall_words = sorted(set(all_words))\ntags = sorted(set(tags))\nprint(tags)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.529229Z","iopub.execute_input":"2024-08-17T07:13:35.530017Z","iopub.status.idle":"2024-08-17T07:13:35.628692Z","shell.execute_reply.started":"2024-08-17T07:13:35.529972Z","shell.execute_reply":"2024-08-17T07:13:35.627605Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['admission', 'canteen', 'college intake', 'committee', 'computerhod', 'course', 'creator', 'document', 'event', 'extchod', 'facilities', 'fees', 'floors', 'goodbye', 'greeting', 'hod', 'hostel', 'hours', 'infrastructure', 'ithod', 'library', 'location', 'menu', 'name', 'number', 'placement', 'principal', 'ragging', 'random', 'salutaion', 'scholarship', 'sem', 'sports', 'swear', 'syllabus', 'task', 'uniform']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Cont..\n\nx_train = []\ny_train = []\n\nfor (pattern_sentance,tag) in xy:\n    bag = nltk_process.bag_of_words(pattern_sentance,all_words)\n    x_train.append(bag)\n\n    label = tags.index(tag)\n\n    y_train.append(label)\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.630626Z","iopub.execute_input":"2024-08-17T07:13:35.630978Z","iopub.status.idle":"2024-08-17T07:13:35.684884Z","shell.execute_reply.started":"2024-08-17T07:13:35.630948Z","shell.execute_reply":"2024-08-17T07:13:35.683606Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Hyper-parameters \nnum_epochs = 1000\nbatch_size = 7\nlearning_rate = 0.001\ninput_size = len(x_train[0])\nhidden_size = 7\noutput_size = len(tags)\nprint(input_size, output_size)\n\ndataset = ChatDataset()\ntrain_loader = DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True,\n                          num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.686538Z","iopub.execute_input":"2024-08-17T07:13:35.686952Z","iopub.status.idle":"2024-08-17T07:13:35.694675Z","shell.execute_reply.started":"2024-08-17T07:13:35.686916Z","shell.execute_reply":"2024-08-17T07:13:35.693091Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"243 37\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = NeuralNet(input_size, hidden_size, output_size).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:35.696394Z","iopub.execute_input":"2024-08-17T07:13:35.696831Z","iopub.status.idle":"2024-08-17T07:13:37.426888Z","shell.execute_reply.started":"2024-08-17T07:13:35.696763Z","shell.execute_reply":"2024-08-17T07:13:37.425675Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Train the model\nfor epoch in range(num_epochs):\n    for (words, labels) in train_loader:\n        words = words.to(device)\n        labels = labels.to(dtype=torch.long).to(device)\n        \n        # Forward pass\n        outputs = model(words)\n        # if y would be one-hot, we must apply\n        # labels = torch.max(labels, 1)[1]\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    if (epoch+1) % 100 == 0:\n        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n\nprint(f'final loss: {loss.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:13:37.428338Z","iopub.execute_input":"2024-08-17T07:13:37.428855Z","iopub.status.idle":"2024-08-17T07:15:00.945696Z","shell.execute_reply.started":"2024-08-17T07:13:37.428824Z","shell.execute_reply":"2024-08-17T07:15:00.944568Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch [100/1000], Loss: 0.0243\nEpoch [200/1000], Loss: 0.0009\nEpoch [300/1000], Loss: 0.0040\nEpoch [400/1000], Loss: 0.0000\nEpoch [500/1000], Loss: 0.0000\nEpoch [600/1000], Loss: 0.0000\nEpoch [700/1000], Loss: 0.0000\nEpoch [800/1000], Loss: 0.0000\nEpoch [900/1000], Loss: 0.0000\nEpoch [1000/1000], Loss: 0.0000\nfinal loss: 0.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Save the Trained Model\n\ndata = {\n\"model_state\": model.state_dict(),\n\"input_size\": input_size,\n\"hidden_size\": hidden_size,\n\"output_size\": output_size,\n\"all_words\": all_words,\n\"tags\": tags\n}\n\nFILE = \"data.pth\"\ntorch.save(data, FILE)\n\nprint(f'training complete. file saved to {FILE}')","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:15:00.947103Z","iopub.execute_input":"2024-08-17T07:15:00.947435Z","iopub.status.idle":"2024-08-17T07:15:00.955883Z","shell.execute_reply.started":"2024-08-17T07:15:00.947408Z","shell.execute_reply":"2024-08-17T07:15:00.954633Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"training complete. file saved to data.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"def chatBot():\n    FILE = \"data.pth\"\n    data = torch.load(FILE)\n\n    input_size = data[\"input_size\"]\n    hidden_size = data[\"hidden_size\"]\n    output_size = data[\"output_size\"]\n    all_words = data['all_words']\n    tags = data['tags']\n    model_state = data[\"model_state\"]\n\n    model = NeuralNet(input_size, hidden_size, output_size).to(device)\n    model.load_state_dict(model_state)\n    model.eval()\n\n    bot_name = \"QuartZ\"\n    print(\"Let's chat! (type 'quit' to exit)\")\n    while True:\n        # sentence = \"do you use credit cards?\"\n        sentence = input(\"You: \")\n        if sentence == \"quit\":\n            break\n\n        sentence = nltk_process.tokenize(sentence)\n        X = nltk_process.bag_of_words(sentence, all_words)\n        X = X.reshape(1, X.shape[0])\n        X = torch.from_numpy(X).to(device)\n\n        output = model(X)\n        _, predicted = torch.max(output, dim=1)\n\n        tag = tags[predicted.item()]\n\n        probs = torch.softmax(output, dim=1)\n        prob = probs[0][predicted.item()]\n        if prob.item() > 0.75:\n            for intent in intents['intents']:\n                if tag == intent[\"tag\"]:\n                    print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n        else:\n            print(f\"{bot_name}: I do not understand...\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:15:00.957350Z","iopub.execute_input":"2024-08-17T07:15:00.957693Z","iopub.status.idle":"2024-08-17T07:15:00.969428Z","shell.execute_reply.started":"2024-08-17T07:15:00.957665Z","shell.execute_reply":"2024-08-17T07:15:00.968290Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"## Run the ChatBot-MKCE\nchatBot()","metadata":{"execution":{"iopub.status.busy":"2024-08-17T07:15:00.972854Z","iopub.execute_input":"2024-08-17T07:15:00.973959Z","iopub.status.idle":"2024-08-17T07:19:26.523529Z","shell.execute_reply.started":"2024-08-17T07:15:00.973918Z","shell.execute_reply":"2024-08-17T07:19:26.522304Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Let's chat! (type 'quit' to exit)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Hi\n"},{"name":"stdout","text":"QuartZ: Hello!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  who made you\n"},{"name":"stdout","text":"QuartZ: I was created by Kavin\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  timing of college\n"},{"name":"stdout","text":"QuartZ: College is open 8.40am-5pm Monday-Saturday!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  what are the courses offered in your college?\n"},{"name":"stdout","text":"QuartZ: Our university offers Information Technology, Computer Engineering, Mechanical engineering, Civil engineering, Electranical Engineering, Electrical and Communication Engineering, Artificial Intelligence & Data Science and Artificial Intelligence and Data Science\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Hod\n"},{"name":"stdout","text":"QuartZ: HODs differ for each branch, please be more specific like: (HOD it)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  hod it\n"},{"name":"stdout","text":"QuartZ: All engineering departments have only one hod XYZ who available on (Place name)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  AI hod\n"},{"name":"stdout","text":"QuartZ: HODs differ for each branch, please be more specific like: (HOD it)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  Who is computer HOD\n"},{"name":"stdout","text":"QuartZ: All engineering departments have only one hod JXXXX who available on 1st Block 3rd Floor\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  principal name\n"},{"name":"stdout","text":"QuartZ: P.S. Murugan is college principal and if you need any help then call your branch hod first. That is more appropriate\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  number of seats per branch\n"},{"name":"stdout","text":"QuartZ: For IT, Computer and extc 60 per branch and seat may be differ for different department.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  college dresscode\n"},{"name":"stdout","text":"QuartZ: No Uniform but dress code is mandatory- Boys- Formal-Casual [Shirt & Pants]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  quit\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}